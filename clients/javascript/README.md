# Log Collector - JavaScript/Node.js Client

ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ë¡œê·¸ ìˆ˜ì§‘ í´ë¼ì´ì–¸íŠ¸ for JavaScript/Node.js

[![Node Version](https://img.shields.io/badge/node-12%2B-green)](https://nodejs.org/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

## ğŸ“‹ Prerequisites

Before using this library, ensure you have:

- **Node.js 14+** or **Browser** (modern browsers with Web Worker support)
- **Package manager**: npm or yarn
- **Log server running**: See [Log Save Server Setup](../../services/log-save-server/README.md)
- **PostgreSQL database**: For log storage (v12+)
- **Basic async knowledge**: Understanding of async/await and Promise patterns

## ğŸ¯ Why Use This Library?

### The Problem
Traditional logging blocks your application, creating performance bottlenecks:
- Each log = 1 HTTP request = ~50ms blocked time
- 100 logs/sec = 5 seconds of blocking per second (impossible!)
- Application threads wait for network I/O
- Database connection pool exhaustion

### The Solution
Asynchronous batch logging with zero blocking:
- âœ… **~0.01ms per log** - App never blocks waiting for network
- âœ… **Batches 1000 logs** - Single HTTP request instead of 1000
- âœ… **Background workers** - Web Worker/Worker Threads handle transmission
- âœ… **Auto compression** - gzip reduces bandwidth by ~70%
- âœ… **Reliable delivery** - Automatic retries with exponential backoff
- âœ… **Graceful shutdown** - Flushes queue before exit, zero log loss

### When to Use This
- High-traffic applications (>100 requests/sec)
- Performance-critical paths where blocking is unacceptable
- Microservices needing centralized structured logging
- Distributed tracing across services
- PostgreSQL-based log analysis and querying

### When NOT to Use This
- Low-traffic apps (<10 req/sec) - simple file logging is fine
- Quick debugging sessions - use console.log for speed
- Need real-time log streaming - use dedicated streaming solutions
- Cannot run log server infrastructure - use cloud logging services

## ğŸš€ Quick Start (30 seconds)

### Step 1: Install
```bash
npm install log-collector-async
# or
yarn add log-collector-async
```

### Step 2: Use in your app
```javascript
import { createLogClient } from 'log-collector-async';

// Initialize logger
const logger = createLogClient('http://localhost:8000');

// Send logs - non-blocking, ~0.01ms
logger.info('Hello world!', { user_id: '123', action: 'test' });
logger.warn('High memory usage', { memory_mb: 512 });
logger.error('Database error', { error: 'connection timeout' });

// Logs are batched and sent automatically every 1 second or 1000 logs
```

### Step 3: Check logs in database
```bash
psql -h localhost -U postgres -d logs_db \
  -c "SELECT * FROM logs ORDER BY created_at DESC LIMIT 5;"
```

**Want more details?** See [Framework Integration](#http-ì»¨í…ìŠ¤íŠ¸-ìë™-ìˆ˜ì§‘) below.

**Want a working example?** Check out [Demo Applications](#-live-demo).

## ğŸ“º Live Demo

See working examples with full context tracking:

### JavaScript + Express
- **Location**: [tests/demo-app/backend/](../../tests/demo-app/backend/)
- **Features**: Login, CRUD operations, error handling, slow API testing
- **Run**: `node tests/demo-app/backend/server.js`

### Python + FastAPI
- **Location**: [tests/demo-app/backend-python/](../../tests/demo-app/backend-python/)
- **Features**: Same features but with Python
- **Run**: `python tests/demo-app/backend-python/server.py`

### Frontend Integration
- **Location**: [tests/demo-app/frontend/](../../tests/demo-app/frontend/)
- **Features**: Browser-based logging with proper CORS setup
- **Run**: Open `tests/demo-app/frontend/index.html` in browser

### Quick Demo Setup
```bash
# 1. Start log server (in Docker)
cd services/log-save-server
docker-compose up

# 2. Start backend (JavaScript or Python)
cd tests/demo-app/backend
node server.js

# 3. Open frontend
open ../frontend/index.html

# 4. Interact with app, then check logs
psql -h localhost -U postgres -d logs_db \
  -c "SELECT service, level, message FROM logs ORDER BY created_at DESC LIMIT 10;"
```

## ğŸ”— Integration with Full System

This client is part of a complete log analysis system. See the [main README](../../README.md) for the full picture.

### System Architecture

```
[Your App] â†’ [JavaScript Client] â†’ [Log Save Server] â†’ [PostgreSQL] â†’ [Analysis Server] â†’ [Frontend]
```

### Related Components

- **Log Save Server**: Receives logs via HTTP POST ([README](../../services/log-save-server/README.md))
- **Log Analysis Server**: Text-to-SQL with Claude Sonnet 4.5 ([README](../../services/log-analysis-server/README.md))
- **Frontend Dashboard**: Svelte 5 web interface ([README](../../frontend/README.md))
- **Python Client**: Python async log collection ([README](../python/README.md))
- **Database Schema**: PostgreSQL 15 with 21 fields ([schema.sql](../../database/schema.sql))

### Quick System Setup

For a complete local environment with all components:

```bash
# From root directory
docker-compose up -d
# Starts: PostgreSQL, Log Save Server, Log Analysis Server, Frontend
```

See [QUICKSTART.md](../../QUICKSTART.md) for detailed setup.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- âš¡ **ë¹„ë¸”ë¡œí‚¹ ë¡œê¹…** - ì•± ë¸”ë¡œí‚¹ < 0.01ms (Web Worker/Worker Threads)
- ğŸš€ **ë°°ì¹˜ ì „ì†¡** - 1000ê±´ or 1ì´ˆë§ˆë‹¤ ìë™ ì „ì†¡
- ğŸ“¦ **ìë™ ì••ì¶•** - gzip ì••ì¶•ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ë¹„ìš© ì ˆê°
- ğŸ”„ **Graceful Shutdown** - ì•± ì¢…ë£Œ ì‹œ í ìë™ flush
- ğŸ¯ **ìë™ í•„ë“œ ìˆ˜ì§‘** - í˜¸ì¶œ ìœ„ì¹˜, HTTP ì»¨í…ìŠ¤íŠ¸, ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ìë™ í¬í•¨
- ğŸŒ **ì›¹ í”„ë ˆì„ì›Œí¬ í†µí•©** - Express, Fastify, Koa ì§€ì›
- ğŸ” **ë¶„ì‚° ì¶”ì ** - trace_idë¡œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ ìš”ì²­ ì¶”ì 

## ğŸ“¦ Installation

```bash
npm install log-collector-async
# or
yarn add log-collector-async
```

## ğŸ’¡ Basic Usage

### Node.js

```javascript
import { createLogClient } from 'log-collector-async';

// Initialize with options
const logger = createLogClient('http://localhost:8000', {
    service: 'my-service',
    environment: 'production',
    serviceVersion: 'v1.0.0'
});

// Send logs (non-blocking, batched automatically)
logger.info('Application started');
logger.warn('High memory usage detected', { memory_mb: 512 });
logger.error('Database connection failed', { db_host: 'localhost' });

// Automatic graceful shutdown on process exit
```

### Browser

```javascript
import { WebWorkerLogClient } from 'log-collector-async/browser';

const logger = new WebWorkerLogClient('http://localhost:8000', {
    service: 'web-app',
    environment: 'production'
});

logger.info('User action', { page: '/dashboard' });
```

### Environment Variables

`.env` file or environment variables (Vite, Webpack supported):
```bash
VITE_LOG_SERVER_URL=http://localhost:8000
VITE_SERVICE_NAME=payment-api
VITE_ENVIRONMENT=production
VITE_SERVICE_VERSION=v1.2.3
VITE_LOG_TYPE=BACKEND
```

```javascript
// Auto-load from environment variables
const logger = createLogClient();
```

## ğŸ¯ Feature 1: ìë™ í˜¸ì¶œ ìœ„ì¹˜ ì¶”ì 

**ëª¨ë“  ë¡œê·¸ì— `function_name`, `file_path` ìë™ í¬í•¨!**

```javascript
function processPayment(amount) {
    logger.info('Processing payment', { amount });
    // â†’ function_name="processPayment", file_path="/app/payment.js" ìë™ í¬í•¨!
}

// ë¹„í™œì„±í™”ë„ ê°€ëŠ¥
logger.log('INFO', 'Manual log', { autoCaller: false });
```

**PostgreSQL ë¶„ì„:**
```sql
SELECT function_name, COUNT(*) as call_count
FROM logs
WHERE created_at > NOW() - INTERVAL '1 hour'
GROUP BY function_name
ORDER BY call_count DESC;
```

## ğŸŒ Feature 2: HTTP ì»¨í…ìŠ¤íŠ¸ ìë™ ìˆ˜ì§‘

**ì›¹ í”„ë ˆì„ì›Œí¬ í™˜ê²½ì—ì„œ `path`, `method`, `ip` ìë™ í¬í•¨!**

### Express í†µí•©

```javascript
import express from 'express';
import crypto from 'crypto';
import { createLogClient } from 'log-collector-async';

const app = express();
const logger = createLogClient('http://localhost:8000');

// HTTP ì»¨í…ìŠ¤íŠ¸ ë¯¸ë“¤ì›¨ì–´ - ìš”ì²­ë§ˆë‹¤ ì»¨í…ìŠ¤íŠ¸ ê°ì²´ ìƒì„±
app.use((req, res, next) => {
    // ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ë¥¼ req ê°ì²´ì— ì €ì¥
    req.logContext = {
        path: req.path,
        method: req.method,
        ip: req.ip,
        trace_id: req.headers['x-trace-id'] || crypto.randomUUID().replace(/-/g, '').substring(0, 32)
    };

    // ì‚¬ìš©ì IDê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (req.headers['x-user-id']) {
        req.logContext.user_id = req.headers['x-user-id'];
    }

    // ìš”ì²­ ì‹œì‘ ë¡œê·¸
    logger.info('Request received', req.logContext);

    const startTime = Date.now();

    // ì‘ë‹µ ì™„ë£Œ ì‹œ ë¡œê·¸
    res.on('finish', () => {
        const duration_ms = Date.now() - startTime;
        logger.info('Request completed', {
            ...req.logContext,
            status_code: res.statusCode,
            duration_ms
        });
    });

    next();
});

app.get('/api/users/:userId', (req, res) => {
    // ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì „ë‹¬
    logger.info(`Fetching user ${req.params.userId}`, {
        ...req.logContext,
        user_id_param: req.params.userId
    });
    // â†’ path, method, ip, trace_id ëª¨ë‘ ìë™ í¬í•¨!
    res.json({ userId: req.params.userId });
});

app.post('/api/todos', (req, res) => {
    logger.info('Creating todo', {
        ...req.logContext,
        todo_text: req.body.text
    });
    // ... handle todo creation
    res.json({ success: true });
});

app.listen(3000);
```

### Fastify í†µí•©

```javascript
import Fastify from 'fastify';
import crypto from 'crypto';
import { createLogClient } from 'log-collector-async';

const fastify = Fastify();
const logger = createLogClient('http://localhost:8000');

// onRequest Hook: HTTP ì»¨í…ìŠ¤íŠ¸ ìƒì„±
fastify.addHook('onRequest', async (request, reply) => {
    // ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ë¥¼ request ê°ì²´ì— ì €ì¥
    request.logContext = {
        path: request.url,
        method: request.method,
        ip: request.ip,
        trace_id: request.headers['x-trace-id'] || crypto.randomUUID().replace(/-/g, '').substring(0, 32)
    };

    // ì‚¬ìš©ì IDê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (request.headers['x-user-id']) {
        request.logContext.user_id = request.headers['x-user-id'];
    }

    // ìš”ì²­ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    request.startTime = Date.now();

    // ìš”ì²­ ì‹œì‘ ë¡œê·¸
    logger.info('Request received', request.logContext);
});

// onResponse Hook: ì‘ë‹µ ì™„ë£Œ ë¡œê·¸
fastify.addHook('onResponse', async (request, reply) => {
    const duration_ms = Date.now() - request.startTime;
    logger.info('Request completed', {
        ...request.logContext,
        status_code: reply.statusCode,
        duration_ms
    });
});

fastify.get('/api/users/:userId', async (request, reply) => {
    // ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì „ë‹¬
    logger.info(`Fetching user ${request.params.userId}`, {
        ...request.logContext,
        user_id_param: request.params.userId
    });
    // â†’ path, method, ip, trace_id ëª¨ë‘ ìë™ í¬í•¨!
    return { userId: request.params.userId };
});

fastify.post('/api/todos', async (request, reply) => {
    logger.info('Creating todo', {
        ...request.logContext,
        todo_text: request.body.text
    });
    // ... handle todo creation
    return { success: true };
});

await fastify.listen({ port: 3000 });
```

### Koa í†µí•©

```javascript
import Koa from 'koa';
import crypto from 'crypto';
import { createLogClient } from 'log-collector-async';

const app = new Koa();
const logger = createLogClient('http://localhost:8000');

// HTTP ì»¨í…ìŠ¤íŠ¸ ë¯¸ë“¤ì›¨ì–´
app.use(async (ctx, next) => {
    // ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ë¥¼ ctx.stateì— ì €ì¥
    ctx.state.logContext = {
        path: ctx.path,
        method: ctx.method,
        ip: ctx.ip,
        trace_id: ctx.headers['x-trace-id'] || crypto.randomUUID().replace(/-/g, '').substring(0, 32)
    };

    // ì‚¬ìš©ì IDê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (ctx.headers['x-user-id']) {
        ctx.state.logContext.user_id = ctx.headers['x-user-id'];
    }

    // ìš”ì²­ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    const startTime = Date.now();

    // ìš”ì²­ ì‹œì‘ ë¡œê·¸
    logger.info('Request received', ctx.state.logContext);

    try {
        await next();

        // ì‘ë‹µ ì™„ë£Œ ë¡œê·¸
        const duration_ms = Date.now() - startTime;
        logger.info('Request completed', {
            ...ctx.state.logContext,
            status_code: ctx.status,
            duration_ms
        });
    } catch (err) {
        // ì—ëŸ¬ ë°œìƒ ë¡œê·¸
        logger.error('Request failed', {
            ...ctx.state.logContext,
            error: err.message,
            stack_trace: err.stack
        });
        throw err;
    }
});

// ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬
app.use(async (ctx) => {
    if (ctx.path === '/api/users' && ctx.method === 'GET') {
        logger.info('Fetching users', ctx.state.logContext);
        // â†’ path, method, ip, trace_id ëª¨ë‘ ìë™ í¬í•¨!
        ctx.body = { users: [] };
    } else if (ctx.path === '/api/todos' && ctx.method === 'POST') {
        logger.info('Creating todo', {
            ...ctx.state.logContext,
            todo_text: ctx.request.body.text
        });
        ctx.body = { success: true };
    } else {
        ctx.body = { message: 'Hello' };
    }
});

app.listen(3000);
```

## ğŸ‘¤ Feature 3: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

**`user_id`, `trace_id`, `session_id` ë“±ì„ ëª¨ë“  ë¡œê·¸ì— ìë™ í¬í•¨!**

### runWithUserContext ë°©ì‹ (ê¶Œì¥)

```javascript
import { createLogClient } from 'log-collector-async';

const logger = createLogClient('http://localhost:8000');

// íŠ¹ì • ë¸”ë¡ì—ë§Œ ì»¨í…ìŠ¤íŠ¸ ì ìš©
logger.constructor.runWithUserContext({
    user_id: 'user_123',
    trace_id: 'trace_xyz',
    session_id: 'sess_abc'
}, () => {
    logger.info('User logged in');
    // â†’ user_id, trace_id, session_id ìë™ í¬í•¨!

    processPayment();
    logger.info('Payment completed');
    // â†’ í•˜ìœ„ í•¨ìˆ˜ì—ì„œë„ ìë™ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€!
});

// ë¸”ë¡ ë²—ì–´ë‚˜ë©´ ìë™ ì´ˆê¸°í™”
```

### ë¹„ë™ê¸° í•¨ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©

```javascript
await logger.constructor.runWithUserContext({
    user_id: 'user_456',
    trace_id: 'trace_async_123'
}, async () => {
    logger.info('Async operation started');
    // â†’ user_id, trace_id ìë™ í¬í•¨

    await fetchUserData();
    await processData();

    logger.info('Async operation completed');
    // â†’ ê°™ì€ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¨
});
```

### ì¤‘ì²© ì»¨í…ìŠ¤íŠ¸ (ìë™ ë³‘í•©)

```javascript
// ì™¸ë¶€: tenant_id
logger.constructor.runWithUserContext({ tenant_id: 'tenant_1' }, () => {
    logger.info('Tenant operation');
    // â†’ tenant_id="tenant_1"

    // ë‚´ë¶€: user_id ì¶”ê°€
    logger.constructor.runWithUserContext({ user_id: 'user_123' }, () => {
        logger.info('User operation');
        // â†’ tenant_id="tenant_1", user_id="user_123" ë‘˜ ë‹¤ í¬í•¨!
    });
});
```

### ë¶„ì‚° ì¶”ì  (Distributed Tracing)

```javascript
import { v4 as uuidv4 } from 'uuid';

function handleRequest() {
    // ìš”ì²­ë§ˆë‹¤ ê³ ìœ í•œ trace_id ìƒì„± (32ì, ëŒ€ì‹œ ì œê±°)
    const traceId = uuidv4().replace(/-/g, '');

    logger.constructor.runWithUserContext({
        trace_id: traceId,
        user_id: 'user_123'
    }, () => {
        logger.info('Request received');
        callServiceA();  // Service A í˜¸ì¶œ
        callServiceB();  // Service B í˜¸ì¶œ
        logger.info('Request completed');
        // â†’ ëª¨ë“  ë¡œê·¸ê°€ ê°™ì€ trace_idë¡œ ì¶”ì  ê°€ëŠ¥!
    });
}
```

**PostgreSQL ë¶„ì„:**
```sql
-- trace_idë¡œ ì „ì²´ ìš”ì²­ íë¦„ ì¶”ì 
SELECT created_at, service, function_name, message, duration_ms
FROM logs
WHERE metadata->>'trace_id' = 'your-trace-id'
ORDER BY created_at;
```

### Set/Clear ë°©ì‹

```javascript
// ë¡œê·¸ì¸ ì‹œ
logger.constructor.setUserContext({
    user_id: 'user_123',
    session_id: 'sess_abc'
});

logger.info('User action');
// â†’ user_id, session_id ìë™ í¬í•¨

// ë¡œê·¸ì•„ì›ƒ ì‹œ
logger.constructor.clearUserContext();
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### íƒ€ì´ë¨¸ ì¸¡ì •

```javascript
// ìˆ˜ë™ íƒ€ì´ë¨¸
const timer = logger.startTimer();
const result = expensiveOperation();
logger.endTimer(timer, 'INFO', 'Operation completed');
// â†’ duration_ms ìë™ ê³„ì‚°

// í•¨ìˆ˜ ë˜í¼ (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)
const result = logger.measure(() => expensiveOperation());
```

### ì—ëŸ¬ ì¶”ì 

```javascript
try {
    riskyOperation();
} catch (err) {
    logger.errorWithTrace('Operation failed', err);
    // â†’ stack_trace, error_type, function_name, file_path ìë™ í¬í•¨!
}
```

### ìˆ˜ë™ Flush

```javascript
// ì¤‘ìš”í•œ ë¡œê·¸ë¥¼ ì¦‰ì‹œ ì „ì†¡
logger.flush();
```

### í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ

```javascript
// Graceful shutdown
await logger.close();
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

```javascript
const logger = createLogClient('http://localhost:8000', {
    service: 'payment-api',
    environment: 'production',
    serviceVersion: 'v1.2.3',
    logType: 'BACKEND',
    batchSize: 1000,          // ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 1000)
    flushInterval: 1000,      // Flush ê°„ê²© ms (ê¸°ë³¸: 1000)
    enableCompression: true   // gzip ì••ì¶• (ê¸°ë³¸: true)
});
```

## ğŸ“Š ì„±ëŠ¥

- **ì•± ë¸”ë¡œí‚¹**: < 0.01ms per log (Web Worker/Worker Threads)
- **ì²˜ë¦¬ëŸ‰**: > 10,000 logs/sec
- **ë©”ëª¨ë¦¬**: < 10MB (1000ê±´ í)
- **ì••ì¶•ë¥ **: ~70% (100ê±´ ì´ìƒ ì‹œ ìë™ ì••ì¶•)

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
npm test

# í†µí•© í…ŒìŠ¤íŠ¸ (ë¡œê·¸ ì„œë²„ í•„ìš”)
npm run test:integration

# ì»¤ë²„ë¦¬ì§€
npm run test:coverage
```

## ğŸ“ ë¡œê·¸ ë ˆë²¨

```javascript
logger.trace('Trace message');    // TRACE
logger.debug('Debug message');    // DEBUG
logger.info('Info message');      // INFO
logger.warn('Warning message');   // WARN
logger.error('Error message');    // ERROR
logger.fatal('Fatal message');    // FATAL
```

## ğŸ” PostgreSQL ì¿¼ë¦¬ ì˜ˆì œ

### ì‚¬ìš©ìë³„ ë¡œê·¸ ì¡°íšŒ
```sql
SELECT * FROM logs
WHERE metadata->>'user_id' = 'user_123'
ORDER BY created_at DESC
LIMIT 100;
```

### ì—ëŸ¬ ë°œìƒë¥ 
```sql
SELECT
    metadata->>'path' as path,
    metadata->>'method' as method,
    COUNT(*) as total_requests,
    COUNT(CASE WHEN level = 'ERROR' THEN 1 END) as errors,
    ROUND(100.0 * COUNT(CASE WHEN level = 'ERROR' THEN 1 END) / COUNT(*), 2) as error_rate
FROM logs
WHERE created_at > NOW() - INTERVAL '1 hour'
GROUP BY metadata->>'path', metadata->>'method'
ORDER BY error_rate DESC;
```

### í•¨ìˆ˜ë³„ ì„±ëŠ¥
```sql
SELECT
    function_name,
    COUNT(*) as calls,
    AVG((metadata->>'duration_ms')::numeric) as avg_ms,
    MAX((metadata->>'duration_ms')::numeric) as max_ms
FROM logs
WHERE metadata->>'duration_ms' IS NOT NULL
GROUP BY function_name
ORDER BY avg_ms DESC;
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **ë¯¼ê°í•œ ì •ë³´ í¬í•¨ ê¸ˆì§€**
   ```javascript
   // âŒ ì ˆëŒ€ ì•ˆ ë¨!
   logger.info('Login', { password: 'secret' });

   // âœ… ì‹ë³„ìë§Œ ì‚¬ìš©
   logger.info('Login successful', { user_id: 'user_123' });
   ```

2. **ê³¼ë„í•œ ë¡œê¹… í”¼í•˜ê¸°**
   ```javascript
   // âŒ ë£¨í”„ ë‚´ë¶€ì—ì„œ ê³¼ë„í•œ ë¡œê¹…
   for (let i = 0; i < 10000; i++) {
       logger.debug(`Processing ${i}`);
   }

   // âœ… ì£¼ìš” ì´ë²¤íŠ¸ë§Œ ë¡œê¹…
   logger.info('Batch processing started', { count: 10000 });
   ```

## ğŸ”§ Troubleshooting

### Logs not appearing in database

**Symptoms**:
- `logger.info()` runs without errors
- No logs visible in PostgreSQL
- No errors in console

**Checklist**:
1. âœ… **Log server running?**
   ```bash
   curl http://localhost:8000/
   # Should return: {"status": "ok"}
   ```

2. âœ… **PostgreSQL running?**
   ```bash
   psql -h localhost -U postgres -d logs_db -c "SELECT 1;"
   ```

3. âœ… **Schema created?**
   ```bash
   psql -h localhost -U postgres -d logs_db -c "\dt"
   # Should show 'logs' table
   ```

4. âœ… **Batch flushed?**
   - Wait 1 second (default flush interval)
   - OR manually flush: `await logger.close()`

5. âœ… **Check server logs**:
   ```bash
   cd services/log-save-server
   docker-compose logs -f
   # Look for "Received X logs" messages
   ```

---

### "Connection refused" errors

**Symptoms**:
```
Error: connect ECONNREFUSED 127.0.0.1:8000
```

**Cause**: Log server not running

**Solution**:
```bash
cd services/log-save-server
docker-compose up -d

# Verify it's running
curl http://localhost:8000/
```

---

### CORS errors (browser only)

**Symptoms**:
```
Access to fetch at 'http://localhost:8000/logs' from origin 'http://localhost:3000'
has been blocked by CORS policy
```

**Cause**: Log server missing CORS configuration

**Solution**: Ensure log server has CORS middleware enabled (already configured in log-save-server)

---

### High memory usage

**Symptoms**:
- Application memory grows over time
- Eventually crashes with OOM error

**Cause**: Batch size too large or flush interval too long

**Solution**: Reduce batching parameters
```javascript
const logger = createLogClient('http://localhost:8000', {
    batchSize: 500,      // Reduce from 1000
    flushInterval: 500   // Reduce from 1000
});
```

---

### Logs delayed or not sent on app shutdown

**Symptoms**:
- Last few logs before shutdown are missing
- Queue not flushing properly

**Cause**: App exits before background worker flushes

**Solution**: Call close before exit
```javascript
// Graceful shutdown
process.on('SIGTERM', async () => {
    await logger.close();  // Flushes queue before closing
    process.exit(0);
});

// Or manually before exit
await logger.close();
```

---

### Worker thread/Web Worker not starting

**Symptoms**:
- Console warnings about worker initialization
- Logs sent synchronously instead of async

**Cause**: Worker script not found or CORS issues in browser

**Solution (Node.js)**: Ensure worker script is included in deployment
```javascript
// worker-node.js should be in node_modules/log-collector-async/dist/
```

**Solution (Browser)**: Serve worker script with correct MIME type
```javascript
// Ensure worker.js is served as application/javascript
```

## ğŸ“‹ Version Compatibility

| Component | Minimum Version | Tested Version | Notes |
|-----------|----------------|----------------|-------|
| **This Client** | 1.0.0 | 1.0.0 | Current release |
| **Log Save Server** | 1.0.0 | 1.0.0 | FastAPI 0.104+ |
| **PostgreSQL** | 12 | 15 | Requires JSONB support |
| **Log Analysis Server** | 1.0.0 | 1.0.0 | Optional (for Text-to-SQL) |
| **Node.js** | 14 | 18 | Runtime environment |

### Breaking Changes

- **v1.0.0**: Initial release

### Upgrade Guide

No upgrades yet. This is the initial release.

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- [HTTP-CONTEXT-GUIDE.md](../HTTP-CONTEXT-GUIDE.md) - HTTP ì»¨í…ìŠ¤íŠ¸ ì™„ì „ ê°€ì´ë“œ
- [USER-CONTEXT-GUIDE.md](../USER-CONTEXT-GUIDE.md) - ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì™„ì „ ê°€ì´ë“œ
- [FIELD-AUTO-COLLECTION.md](../FIELD-AUTO-COLLECTION.md) - ìë™ í•„ë“œ ìˆ˜ì§‘ ìƒì„¸

## ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”!

---

**Made with â¤ï¸ by Log Analysis System Team**
